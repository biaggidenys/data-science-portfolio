{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URA58Tn_HZFS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import openai\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsKIlbxcTy8w"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_patents = pd.read_csv('G:\\\\Meu Drive\\\\Colab Notebooks\\\\Sirius\\\\Projeto Final\\\\resultados_classificados.csv')\n",
        "df_subsetores = pd.read_excel('G:\\\\Meu Drive\\\\Colab Notebooks\\\\Sirius\\\\Projeto Final\\\\Definição de Subsetores.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trbP05IaUFvi"
      },
      "outputs": [],
      "source": [
        "# 2. Pré-processamento dos textos\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = text.replace('\\n', ' ')\n",
        "    return text\n",
        "\n",
        "df_patents['processed_abstract'] = df_patents['abstract'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuz2EOWPUI0b"
      },
      "outputs": [],
      "source": [
        "# 3. Gerar embeddings com BERT\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def gerar_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "\n",
        "df_patents['bert_embedding'] = df_patents['processed_abstract'].apply(gerar_embedding)\n",
        "\n",
        "df_subsetores['bert_embedding'] = df_subsetores['KeyWords'].apply(lambda keywords: gerar_embedding(' '.join(str(keywords).split(','))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1Kus_sWHZFX",
        "outputId": "9ac841be-2932-41ed-ebbe-73863d6d03e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['patent_id', 'Ecosystem', 'class_IPC_concat', 'abstract',\n",
            "       'processed_abstract', 'predicted_subsetor', 'bert_embedding'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_patents.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iC8cIBZHZFZ",
        "outputId": "f9cff19d-cb57-48fe-f356-9578e746ea30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (23508, 768)\n",
            "y_train shape: (23508, 16)\n",
            "X_test shape: (5877, 768)\n",
            "y_test shape: (5877, 16)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\joao_\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3772 - loss: 1.9047 - val_accuracy: 0.4322 - val_loss: 1.6680\n",
            "Epoch 2/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4454 - loss: 1.6672 - val_accuracy: 0.4866 - val_loss: 1.5613\n",
            "Epoch 3/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4756 - loss: 1.5890 - val_accuracy: 0.4710 - val_loss: 1.5610\n",
            "Epoch 4/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4858 - loss: 1.5566 - val_accuracy: 0.4809 - val_loss: 1.5168\n",
            "Epoch 5/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5056 - loss: 1.4924 - val_accuracy: 0.5103 - val_loss: 1.4563\n",
            "Epoch 6/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 1.4477 - val_accuracy: 0.5185 - val_loss: 1.4393\n",
            "Epoch 7/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 1.4359 - val_accuracy: 0.5334 - val_loss: 1.3943\n",
            "Epoch 8/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5272 - loss: 1.4255 - val_accuracy: 0.5288 - val_loss: 1.4279\n",
            "Epoch 9/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 1.3958 - val_accuracy: 0.5338 - val_loss: 1.3934\n",
            "Epoch 10/10\n",
            "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5442 - loss: 1.3733 - val_accuracy: 0.5447 - val_loss: 1.3741\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1752ca18e60>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#codigo ajustado do 4 ao 6\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Preparar dados para classificação\n",
        "X = np.array(df_patents['bert_embedding'].tolist())  # Converter lista de embeddings para np.array\n",
        "y = df_patents['predicted_subsetor'].astype('category').cat.codes\n",
        "\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Verificar shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Criar o modelo de Deep Learning\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # Usa X_train.shape[1] para input_dim\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZ0fzShUMHa"
      },
      "outputs": [],
      "source": [
        "# 4. Preparar dados para classificação\n",
        "\n",
        "X = list(df_patents['bert_embedding'])\n",
        "y = df_patents['predicted_subsetor'].astype('category').cat.codes\n",
        "\n",
        "y = to_categorical(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccWCrZLNUOXc",
        "outputId": "196ca062-ef5e-46e7-af43-c468bf38f10e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\joao_\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# 5. Criar o modelo de Deep Learning\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=len(X_train[0]), activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6gi4W7JHZFb"
      },
      "outputs": [],
      "source": [
        "print(\"Forma de X_train:\", X_train.shape)\n",
        "print(\"Forma de X_test:\", X_test.shape)\n",
        "print(\"Forma de y_train:\", y_train.shape)\n",
        "print(\"Forma de y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XrIfgmeUQ0E"
      },
      "outputs": [],
      "source": [
        "# 6. Treinar o modelo\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi31xObcHZFc",
        "outputId": "4ddbd9fe-3b7f-44e4-f9c8-e111902cd39d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A patente em questão se enquadra mais apropriadamente no subsetor **Fintech**, apesar de haver aspectos que tangenciam outros subsetores como \"Cybersecurity\" e \"Industry 4.0\". Permita-me explicar o porquê dessa escolha:\n",
            "\n",
            "1. **Alinhamento com o Foco do Subsetor**: O resumo descreve um método e aparelho para fornecer redundância em um caixa eletrônico (ATM). Isso se encaixa de forma natural dentro do subsetor Fintech, que abrange inovações tecnológicas aplicadas ao setor financeiro, incluindo a otimização e segurança de operações bancárias e financeiras. Caixas eletrônicos são fundamentais para as operações do dia a dia dos bancos, que são instituições-chave no setor financeiro.\n",
            "\n",
            "2. **Aspect\n"
          ]
        }
      ],
      "source": [
        "# 7. Implementação de Explicação com GPT-4\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# Inicialize o cliente da OpenAI\n",
        "client = OpenAI(api_key=\"xxxxxxxxxxxx\")  # Substitua por sua chave real\n",
        "\n",
        "def gerar_explicacao(abstract, subsetores_relevantes):\n",
        "    subsetores_info = '\\n'.join([f\"Subsetor: {row['Subsetores']}, Palavras-chave: {row['KeyWords']}\" for _, row in subsetores_relevantes.iterrows()])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Você é um especialista em patentes. Abaixo está o resumo de uma patente e os subsetores relevantes com base nas palavras-chave.\n",
        "\n",
        "    Resumo da patente: {abstract}\n",
        "\n",
        "    Subsetores relevantes:\n",
        "    {subsetores_info}\n",
        "\n",
        "    Por favor, categorize essa patente no subsetor mais apropriado e forneça uma explicação detalhada sobre o motivo dessa escolha.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",  # Ou \"gpt-3.5-turbo\"\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você é um especialista em patentes.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=400\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Exemplo de uso\n",
        "test_abstract = df_patents['processed_abstract'].iloc[0]\n",
        "subsetores_relevantes = df_subsetores\n",
        "explicacao = gerar_explicacao(test_abstract, subsetores_relevantes)\n",
        "print(explicacao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfUbUJf1HZFc",
        "outputId": "3f761c36-71f7-4371-87ab-8a0f7823bbd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['patent_id', 'Ecosystem', 'class_IPC_concat', 'abstract',\n",
            "       'processed_abstract', 'predicted_subsetor', 'bert_embedding'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_patents.columns)  # Lista todas as colunas do DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUivzAAaHZFd"
      },
      "outputs": [],
      "source": [
        "# Supondo que seu DataFrame seja chamado df_patents\n",
        "df_patents.to_csv('df_patents.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msp8NeRIHZFe",
        "outputId": "2463bc60-5a99-43a8-9df7-3b5ae65e9639"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: seu_script.py\n",
            "'npx' n�o � reconhecido como um comando interno\n",
            "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
          ]
        }
      ],
      "source": [
        "!streamlit run seu_script.py & npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fztfmZPRUY8I",
        "outputId": "8594bbc5-d4e9-40c5-851a-8fafbb193f61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-30 22:16:31.898 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.899 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.900 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.900 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.905 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.919 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:31.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:34.930 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:34.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:34.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-01-30 22:16:34.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# 9. Dashboard com Streamlit\n",
        "\n",
        "def streamlit_dashboard():\n",
        "    st.title(\"Inteligência de Patentes com IA\")\n",
        "    selected_patent = st.selectbox(\"Selecione uma patente\", df_patents['patent_id'])\n",
        "    selected_row = df_patents[df_patents['patent_id'] == selected_patent]\n",
        "    st.write(\"**Resumo:**\", selected_row['processed_abstract'].values[0])\n",
        "    st.write(\"**Subsetor Previsto:**\", selected_row['predicted_subsetor'].values[0])\n",
        "    st.write(\"**Explicação:**\", gerar_explicacao(selected_row['processed_abstract'].values[0], df_subsetores))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    streamlit_dashboard()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}